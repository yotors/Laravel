{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yotors/Laravel/blob/main/podcast.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzlOKOLkIncB",
        "outputId": "af08901c-2a86-41bc-8611-801b04bea649"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (2.164.0)\n",
            "Requirement already satisfied: google-auth-httplib2 in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.11/dist-packages (1.2.1)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (0.22.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (2.38.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (2.24.2)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (4.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib) (2.0.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.69.2)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (5.29.4)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.26.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (4.9)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client) (3.2.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2\n",
        "!pip install google-api-python-client google-auth-httplib2 google-auth-oauthlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpMSSnJQZQsX"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "from google.colab import auth\n",
        "from google.auth.transport.requests import Request\n",
        "from google.oauth2.credentials import Credentials\n",
        "from IPython.display import display, Javascript\n",
        "import google.generativeai as genai\n",
        "import PyPDF2\n",
        "import os\n",
        "import requests\n",
        "import io\n",
        "import time\n",
        "import subprocess\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_pdf(pdf_url: str) -> str:\n",
        "    \"\"\"Reads a PDF from a URL and returns its content as bytes.\n",
        "\n",
        "    Args:\n",
        "        pdf_url: URL of the PDF file.\n",
        "\n",
        "    Returns:\n",
        "        Raw bytes of the PDF file.\n",
        "    \"\"\"\n",
        "    response = requests.get(pdf_url, stream=True)\n",
        "    response.raise_for_status()\n",
        "    pdf_path = 'pdf_file'\n",
        "    with open(pdf_path, 'wb') as f:\n",
        "        for chunk in response.iter_content(chunk_size=8192):\n",
        "            f.write(chunk)\n",
        "    return pdf_path\n"
      ],
      "metadata": {
        "id": "kczletbG9bxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_content = upload_pdf('http://research.google.com/pubs/archive/34939.pdf')"
      ],
      "metadata": {
        "id": "3JTnc8Rf-mU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "y5Azhas_DNbx",
        "outputId": "48d59b40-3b78-43e7-a6dd-a1c11a8b599d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'pdf_file'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf(pdf_bytes: str)-> str:\n",
        "    \"\"\"Extracts text content from a PDF file.\n",
        "\n",
        "    Args:\n",
        "        pdf_bytes: The raw bytes of a PDF.\n",
        "\n",
        "    Returns:\n",
        "        Extracted text as a string, or None if extraction fails.\n",
        "    \"\"\"\n",
        "    try:\n",
        "      pdf_reader = PyPDF2.PdfReader(pdf_bytes)\n",
        "      text = \"\"\n",
        "      for page in pdf_reader.pages:\n",
        "         text += page.extract_text()\n",
        "      return text\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting text from PDF: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "R2SGuQN_9mVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_text = extract_text_from_pdf(pdf_content)"
      ],
      "metadata": {
        "id": "rg31gP_DCIwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_with_gemini(text:str) -> str:\n",
        "    \"\"\"Summarizes the given text using the Gemini API.\n",
        "\n",
        "    Args:\n",
        "        text: The text to summarize.\n",
        "\n",
        "    Returns:\n",
        "        Summarized text or None if it failed\n",
        "    \"\"\"\n",
        "    api_key = userdata.get('API_KEY')\n",
        "    model = \"gemini-2.0-flash\"\n",
        "    try:\n",
        "        genai.configure(api_key=api_key)\n",
        "        generation_config = genai.GenerationConfig(\n",
        "            temperature=0.7,\n",
        "            top_p=1,\n",
        "            top_k=1,\n",
        "            max_output_tokens=2048,\n",
        "        )\n",
        "        model = genai.GenerativeModel(model_name=model, generation_config=generation_config)\n",
        "        prompt = f\"\"\"\n",
        "        Please summarize the following document into plain text suitable for a podcast script between two persons, Alisa and Bob. Do not use any markdown formatting.\n",
        "\n",
        "        {text}\n",
        "        \"\"\"\n",
        "        response = model.generate_content(prompt)\n",
        "        if response.text:\n",
        "          return response.text\n",
        "        else:\n",
        "          print(\"The Gemini API didn't return any response\")\n",
        "          return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error using Gemini API: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "D8lqSuCC9rII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "summarized_text = summarize_with_gemini(extracted_text, gemini_api_key)"
      ],
      "metadata": {
        "id": "wr2YUjq2Ea8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarized_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "SYlAzG8NFDAA",
        "outputId": "0c397d90-222c-4f18-c47b-bcdbc1c06d34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Alisa: Hey Bob, heard about this interesting paper on how to represent programs for AI?\\n\\nBob: Oh yeah? What\\'s it about? I always thought programs were just… code.\\n\\nAlisa: Well, the paper argues that for AI to really learn and reason, especially for Artificial General Intelligence (AGI), the way we *represent* programs matters a lot. Traditional machine learning uses simple data formats, but real-world stuff is complex with relationships, hierarchies, and all that.\\n\\nBob: So, programs are a way to handle that complexity?\\n\\nAlisa: Exactly! The paper says programs are well-defined, compact, and hierarchical. Unlike natural language, programs aren\\'t ambiguous. They can compress data and are built from sub-programs.\\n\\nBob: Okay, I get the structure part. But why not just use neural networks?\\n\\nAlisa: The paper mentions that! Neural nets can be opaque and inefficient. This paper is looking for something better than just throwing tons of processing power at the problem.\\n\\nBob: So, what\\'s the big challenge?\\n\\nAlisa: A few! \"Open-endedness\" means programs can be any size, so you can\\'t easily represent them in a fixed space. Then there\\'s \"over-representation,\" meaning different code can do the same thing, wasting resources. And \"chaotic execution\" – tiny code changes can have huge effects making it hard to search for solutions. Finally, \"high resource-variance\" means some programs take way more compute power than others.\\n\\nBob: Sounds like a mess. How do they propose to fix it?\\n\\nAlisa: They suggest using \"normal forms\" and transformations. Normal forms are like standardized ways of writing code that make it easier to understand and manipulate.\\n\\nBob: Like, making sure all \"if\" statements are written the same way?\\n\\nAlisa: Kind of! They have normal forms for different data types: Booleans, numbers, lists, tuples, functions, and even actions that interact with the world. Each type has its own set of rules and functions.\\n\\nBob: Okay, so everything is standardized. What about these transformations?\\n\\nAlisa: Transformations are ways to change the code while (hopefully) preserving its meaning. They talk about \"reductions\" which simplify the code, \"neutral transformations\" which change the structure without changing the meaning, and \"non-neutral transformations\" which can change the meaning but hopefully get you closer to a solution.\\n\\nBob: So, it\\'s like refactoring code, but for AI learning?\\n\\nAlisa: Pretty much! The goal is to make it easier for the AI to explore the space of possible programs efficiently. They even talk about using a \"fold\" function, which helps create loops and iterative processes in a controlled way.\\n\\nBob: Sounds complicated, but interesting. So, the AI can learn and reason about programs better?\\n\\nAlisa: That\\'s the hope! The paper says it\\'s all about finding the right balance between exploring new programs and exploiting what you already know. They even mention using heuristics to decide which code changes are most likely to be useful.\\n\\nBob: So, what\\'s next for this research?\\n\\nAlisa: They want to test these normal forms and transformations to see if they really do make it easier to find good programs. They also want to use them in program evolution systems, where programs are automatically improved over time.\\n\\nBob: Cool! Sounds like a step towards smarter AI. Thanks for explaining it, Alisa!\\n\\nAlisa: No problem, Bob! Always happy to share some AI geekiness.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_podcast_from_text(text:str, api_url:str, api_key:str, voice_id:str, output_file:str) -> str:\n",
        "    \"\"\"\n",
        "    Placeholder function to generate a podcast using an AI service.\n",
        "    Replace this with your API integration logic.\n",
        "\n",
        "    Args:\n",
        "        text: The text extracted from the PDF.\n",
        "        api_url: The URL endpoint of the AI service API.\n",
        "        api_key: API key for the chosen AI service.\n",
        "        voice_id: specific voice id for this specific AI service\n",
        "        output_file: The path to save the generated audio file.\n",
        "\n",
        "    Returns:\n",
        "        Path to the downloaded audio file or None if it failed\n",
        "    \"\"\"\n",
        "    try:\n",
        "        headers = {\n",
        "            \"xi-api-key\": api_key,\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        }\n",
        "        data = {\n",
        "          \"text\": text,\n",
        "          \"model_id\": \"eleven_multilingual_v1\",\n",
        "          \"voice_settings\": {\n",
        "              \"stability\": 0.5,\n",
        "              \"similarity_boost\": 0.5\n",
        "            }\n",
        "        }\n",
        "        response = requests.post(f\"{api_url}/text-to-speech/{voice_id}\", headers=headers, json=data, stream=True)\n",
        "        if response.status_code == 200:\n",
        "             with open(output_file, \"wb\") as f:\n",
        "                for chunk in response.iter_content(chunk_size=512):\n",
        "                     if chunk:\n",
        "                           f.write(chunk)\n",
        "             return output_file\n",
        "        else:\n",
        "            print(f\"Error with API request, status code {response.status_code}: {response.content}\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "      print(f\"Error calling the AI API: {e}\")\n",
        "      return None"
      ],
      "metadata": {
        "id": "3yVxTfpu94hS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_duo_podcast(text:str)-> None:\n",
        "    \"\"\"\n",
        "    Generates a podcast with two speakers by alternating between paragraphs\n",
        "\n",
        "    Args:\n",
        "        text: The full text content.\n",
        "\n",
        "    Returns:\n",
        "        Path to the merged audio file or None if it fails\n",
        "    \"\"\"\n",
        "    api_url = \"https://api.elevenlabs.io/v1\"\n",
        "    api_key = userdata.get('ELEVEN')\n",
        "    voice_id_1 = \"9BWtsMINqrJLrRacOk9x\"\n",
        "    voice_id_2 = \"cjVigY5qzO86Huf0OWal\"\n",
        "    output_file = \"output_podcast.mp3\"\n",
        "    paragraphs = text.split(\"\\n\\n\")\n",
        "    temp_audio_files = []\n",
        "\n",
        "    for i, paragraph in enumerate(paragraphs):\n",
        "        speaker_id = voice_id_1 if i % 2 == 0 else voice_id_2\n",
        "        temp_file = f\"temp_audio_{i}.mp3\"\n",
        "\n",
        "        temp_audio_path = generate_podcast_from_text(paragraph, api_url, api_key, speaker_id, temp_file)\n",
        "\n",
        "        if temp_audio_path:\n",
        "            temp_audio_files.append(temp_audio_path)\n",
        "        else:\n",
        "            print(\"Error in creating an intermediate audio file\")\n",
        "            # cleanup and return\n",
        "            for file_path in temp_audio_files:\n",
        "                try:\n",
        "                    os.remove(file_path)\n",
        "                except OSError:\n",
        "                   pass\n",
        "            return None\n",
        "\n",
        "    # concatenate the audio files (simple sequential combination)\n",
        "    try:\n",
        "        with open(output_file, \"wb\") as final_audio:\n",
        "            for audio_file in temp_audio_files:\n",
        "                with open(audio_file, \"rb\") as f:\n",
        "                  final_audio.write(f.read())\n",
        "\n",
        "            for file_path in temp_audio_files:\n",
        "              os.remove(file_path)\n",
        "\n",
        "        return output_file\n",
        "    except Exception as e:\n",
        "      print(f\"Error concatenating audio files: {e}\")\n",
        "      return None"
      ],
      "metadata": {
        "id": "3s5jOzAf980V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "generate_duo_podcast(summarized_text, elevenlabs_api_url, elevenlabs_api_key, elevenlabs_voice_id_1, elevenlabs_voice_id_2, output_audio_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wiohx24LFexF",
        "outputId": "25b32dd7-7d8e-4cb0-ab43-bf36b68c7b21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error with API request, status code 401: b'{\"detail\":{\"status\":\"quota_exceeded\",\"message\":\"This request exceeds your quota of 10000. You have 134 credits remaining, while 206 credits are required for this request.\"}}'\n",
            "Error in creating an intermediate audio file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0O4OWvNX1dhl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "def create_video_from_audio_ffmpeg(audio_filepath:str, output_filepath:str, image_filepath:str) -> str:\n",
        "    \"\"\"\n",
        "    Creates a video from an audio file using FFmpeg with proper syntax.\n",
        "\n",
        "    Args:\n",
        "        audio_filepath: Path to the input audio file.\n",
        "        output_filepath: Path to the output video file.\n",
        "        image_filepath (optional): Path to an image to use as static background.\n",
        "    \"\"\"\n",
        "    # Install ffmpeg if not already present\n",
        "    if not os.path.exists('/usr/bin/ffmpeg'):\n",
        "        print(\"Installing ffmpeg...\")\n",
        "        subprocess.run(['apt-get', 'update'], check=True)\n",
        "        subprocess.run(['apt-get', 'install', '-y', 'ffmpeg'], check=True)\n",
        "\n",
        "    if not os.path.exists(audio_filepath):\n",
        "        raise FileNotFoundError(f\"Audio file not found: {audio_filepath}\")\n",
        "\n",
        "    # Build the correct FFmpeg command\n",
        "    if image_filepath:\n",
        "        if not os.path.exists(image_filepath):\n",
        "            raise FileNotFoundError(f\"Image file not found: {image_filepath}\")\n",
        "\n",
        "        command = [\n",
        "            'ffmpeg',\n",
        "            '-loop', '1',\n",
        "            '-i', image_filepath,\n",
        "            '-i', audio_filepath,\n",
        "            '-vf', 'scale=1280:720:force_original_aspect_ratio=decrease,pad=1280:720:(ow-iw)/2:(oh-ih)/2,setsar=1',\n",
        "            '-c:v', 'libx264',\n",
        "            '-tune', 'stillimage',\n",
        "            '-pix_fmt', 'yuv420p',\n",
        "            '-c:a', 'copy',\n",
        "            '-shortest',\n",
        "            '-y',\n",
        "            output_filepath\n",
        "        ]\n",
        "    else:\n",
        "        command = [\n",
        "            'ffmpeg',\n",
        "            '-f', 'lavfi',\n",
        "            '-i', 'color=c=black:s=1280x720:r=25',\n",
        "            '-i', audio_filepath,\n",
        "            '-c:v', 'libx264',\n",
        "            '-pix_fmt', 'yuv420p',\n",
        "            '-c:a', 'copy',\n",
        "            '-shortest',\n",
        "            '-y',\n",
        "            output_filepath\n",
        "        ]\n",
        "\n",
        "    try:\n",
        "        print(\"Running FFmpeg command:\")\n",
        "        print(' '.join(command))\n",
        "        subprocess.run(command, check=True)\n",
        "        print(f\"Successfully created video: {output_filepath}\")\n",
        "        return output_filepath\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"FFmpeg error: {e.stderr.decode() if e.stderr else str(e)}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {str(e)}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio_file = \"/output_podcast.mp3\"\n",
        "output_video = \"/output_video.mp4\"\n",
        "image_filepath = '/symbolic.png'\n",
        "create_video_from_audio_ffmpeg(audio_file, output_video, image_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "giDAYGBGGKf9",
        "outputId": "48c67d77-d1ae-4fb5-f9c6-a68c342eadf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running FFmpeg command:\n",
            "ffmpeg -loop 1 -i /symbolic.png -i /output_podcast.mp3 -vf scale=1280:720:force_original_aspect_ratio=decrease,pad=1280:720:(ow-iw)/2:(oh-ih)/2,setsar=1 -c:v libx264 -tune stillimage -pix_fmt yuv420p -c:a copy -shortest -y /output_video.mp4\n",
            "Successfully created video: /output_video.mp4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/output_video.mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_authenticated_service() -> str:\n",
        "    \"\"\"Authenticates with YouTube API using OAuth 2.0 credentials.\n",
        "\n",
        "    Guides user through getting OAuth tokens from Google's OAuth Playground and\n",
        "    returns an authenticated YouTube service client.\n",
        "\n",
        "    Args:\n",
        "        oauth_response: JSON string containing access_token, refresh_token, etc.\n",
        "\n",
        "    Returns:\n",
        "        Authenticated YouTube API service client.\n",
        "    \"\"\"\n",
        "    SCOPES = ['https://www.googleapis.com/auth/youtube.upload']\n",
        "\n",
        "    creds_data = json.loads(\"\"\"{\n",
        "  \"access_token\": \"ya29.a0AeXRPp7rm_o2CX5AdZ3YbMf9NoKMAiRCd9Kx18N8BaOxx55mOywt9YZHztU2K9dTjij9uKHJfeVe_nlf51sbZWO251c9u7NFpoI2DF8katdhpKgEtVz0KMFMPhDx44s8SVWFS38yjSc5u1ORGVqUvvICguroynP2rLXZfXDdaCgYKAYISARMSFQHGX2MiGArfw5B1bG9CEapx0r05pQ0175\",\n",
        "  \"refresh_token_expires_in\": 604799,\n",
        "  \"expires_in\": 3599,\n",
        "  \"token_type\": \"Bearer\",\n",
        "  \"scope\": \"https://www.googleapis.com/auth/youtube.channel-memberships.creator https://www.googleapis.com/auth/youtube.readonly https://www.googleapis.com/auth/youtube.upload https://www.googleapis.com/auth/youtube https://www.googleapis.com/auth/youtube.force-ssl https://www.googleapis.com/auth/youtubepartner https://www.googleapis.com/auth/youtubepartner-channel-audit\",\n",
        "  \"refresh_token\": \"1//04y_ssvJXtaSqCgYIARAAGAQSNwF-L9IruwQKG9HCvaxSb05XxVd-CzGJ0lO-ZJPFJ4mLo30hCg8AINkPSb_KVYL2OvRDYzQ6MBk\"\n",
        "}\"\"\")\n",
        "    print(creds_data)\n",
        "    creds = Credentials(\n",
        "        token=creds_data.get('access_token'),\n",
        "        refresh_token=creds_data.get('refresh_token'),\n",
        "        token_uri='https://oauth2.googleapis.com/token',\n",
        "        client_id=creds_data.get('client_id'),\n",
        "        client_secret=creds_data.get('client_secret'),\n",
        "        scopes=SCOPES\n",
        "    )\n",
        "\n",
        "    return build('youtube', 'v3', credentials=creds)\n",
        "\n",
        "def upload_video(\n",
        "    youtube_service: str,\n",
        "    video_path: str,\n",
        "    title: str,\n",
        "    description: str,\n",
        "    category_id: str,\n",
        "    tags: list[str],\n",
        "    privacy_status: str) -> dict:\n",
        "    \"\"\"Uploads a video to YouTube using the authenticated service.\n",
        "\n",
        "    Args:\n",
        "        youtube_service: Authenticated YouTube service\n",
        "        video_path: Local path to video file\n",
        "        title: Video title\n",
        "        description: Video description\n",
        "        category_id: YouTube category ID\n",
        "        tags: List of video tags\n",
        "        privacy_status: Video privacy status\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing YouTube API response with video details\n",
        "    \"\"\"\n",
        "    body = {\n",
        "        'snippet': {\n",
        "            'title': title,\n",
        "            'description': description,\n",
        "            'categoryId': category_id,\n",
        "            'tags': tags\n",
        "        },\n",
        "        'status': {\n",
        "            'privacyStatus': privacy_status\n",
        "        }\n",
        "    }\n",
        "\n",
        "    media = MediaFileUpload(\n",
        "        video_path,\n",
        "        mimetype='video/*',\n",
        "        resumable=True,\n",
        "        chunksize=8*1024*1024  # 8MB chunks\n",
        "    )\n",
        "\n",
        "    request = youtube_service.videos().insert(\n",
        "        part='snippet,status',\n",
        "        body=body,\n",
        "        media_body=media\n",
        "    )\n",
        "\n",
        "    response = None\n",
        "    while response is None:\n",
        "        status, response = request.next_chunk()\n",
        "        if status:\n",
        "            print(f\"Uploaded {int(status.progress() * 100)}%\")\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "ZTyBjByz-NSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rDhUM2T_jI_"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "\n",
        "# create client\n",
        "api_key = userdata.get(\"API_KEY\")\n",
        "client = genai.Client(api_key=api_key)\n",
        "\n",
        "# Define the model you are going to use\n",
        "model_id =  \"gemini-2.0-flash\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.genai.types import GenerateContentConfig\n",
        "config = GenerateContentConfig(\n",
        "    system_instruction=\"You are helpfull agent that uploads a generated video podcast to YouTube. The podcast audio uses ElevenLabs AI voices based on a Gemini-summarized PDF. Automate the upload using available tools.\", # to give the LLM context.\n",
        "    tools=[upload_pdf, extract_text_from_pdf, summarize_with_gemini, generate_podcast_from_text, generate_duo_podcast, create_video_from_audio_ffmpeg, get_authenticated_service, upload_video ], # define the functions that the LLM can use\n",
        ")"
      ],
      "metadata": {
        "id": "2oIxzty2KAoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r = client.models.generate_content(\n",
        "    model=model_id,\n",
        "    config=config,\n",
        "    contents=\"\"\"from this pdf source: \"http://research.google.com/pubs/archive/34939.pdf\" get the pdf and make a podcast save the audio and use /symbolic.png for image in the video\n",
        "     also upload the video to youtube with the title moses project use the discription as evolutionary algorithm with the tags ai, symbolic and icog  .\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "FrxrZIy8KEgn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b302a5a4-8004-4bd8-dfe3-a71a164e6cb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error using Gemini API: module 'google.genai' has no attribute 'configure'\n",
            "Error with API request, status code 404: b'{\"detail\":\"Not Found\"}'\n",
            "Error with API request, status code 400: b'{\"detail\":{\"status\":\"max_character_limit_exceeded\",\"message\":\"This request\\'s text has 29786.0 credits and exceeds the credit limit of 10000 credits. Please use Studio for long form TTS.\"}}'\n",
            "Error in creating an intermediate audio file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(r.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpwK6ZEoOHRs",
        "outputId": "53c9fb18-3cc6-48da-85f2-2310ed931a1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HuBbMVq_WqMH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPUWYwf/ZKe1N3RiXgX1eu5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}